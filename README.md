# AutoML-Efficient-Development-of-Application-Specific-Machine-Learning-Models
With the uptake of machine learning applications for edge devices, we are seeing an increase in model-requirements including memory, bandwidth, and inference time. For many applications these requirements come in the form of upper bounds on several different metrics - something that guarantees an application can be deployed efficiently.    Today, these requirements are met through a combination of both training and post-training work, such as pruning and quantization. However, by relying on post-training work we are increasing both time and uncertainty when developing machine learning applications.    We believe that by using novel hyperparameter optimization techniques, we can significantly reduce the need for post-training work. Our approach is to investigate and formulate application-specific upper bounds and use those as constraints to guide the optimization process. By doing so we are reformulating the problem: from an optimization problem across, at least, three or four different metrics to a search problem for a diverse set of hyperparameter configurations, all of which satisfy our predetermined constraints.    Furthermore, this is a scalable framework with no theoretical limits on the number of metrics in consideration, which permits easier development of increasingly complex applications in future.
