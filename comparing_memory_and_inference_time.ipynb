{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"memory_versus_size.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNx6fZ7DIQt7ulVrX8hDZNi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"jZ1mUbHcYXx6"},"source":["! pip install sigopt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wfGlKsQj9rVp"},"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","from torch.profiler import profile, record_function, ProfilerActivity\n","\n","import numpy as np\n","from skimage import transform\n","\n","import sigopt\n","import os\n","\n","import time\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FQzlUiB5Y62Z"},"source":["os.environ[\"SIGOPT_API_TOKEN\"] = ' insert SigOPT API Token'\n","%load_ext sigopt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uupZBqZuWWHV"},"source":["def get_inference_time(model, input):\n","  \"Estimate inference time\"\n","\n","  Time = []\n","\n","  time_start = time.time()\n","\n","  _ = model(input)\n","\n","  time_end = time.time()\n","\n","  return time_end - time_start"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j25dGJrICEkx"},"source":["def profile_model(model, input):\n","  \"Profile model\"\n","\n","  with profile(activities=[ProfilerActivity.CPU],\n","               profile_memory=True,\n","              with_flops=True,\n","               record_shapes=True) as prof:\n","\n","    with torch.no_grad():\n","      model.forward(input)\n","\n","  return [((e.cpu_memory_usage / 1024.0) / 1024) for e in prof.events() if e.name == 'aten::conv2d'][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_model_size(model):\n","  \"get the size of the stored model in mB\"\n","\n","  torch.save(model.state_dict(), \"tmp.pt\") \n","  size_mb = os.path.getsize(\"tmp.pt\")/1e6\n","  os.remove('tmp.pt')\n","\n","  return size_mb\n"],"metadata":{"id":"8ONio5gkcG8z"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNizcam6YoEd"},"source":["experiment = sigopt.create_experiment(\n","  name=\"Peak memory\",\n","\n","  type=\"random\",\n","\n","  parameters=[     \n","    dict(name=\"in_channels_\", type=\"int\", bounds=dict(min=1, max=20)),\n","    dict(name=\"out_channels_\", type=\"int\", bounds=dict(min=1, max=20)),\n","    dict(name=\"kernel_size_\", type=\"int\", bounds=dict(min=1, max=20)),\n","    dict(name=\"stride_\", type=\"int\", bounds=dict(min=1, max=20)),\n","    dict(name=\"padding_\", type=\"int\", bounds=dict(min=1, max=20)),\n","    dict(name=\"batch_size_\", type=\"int\", bounds=dict(min=1, max=20)),\n","\n","    dict(name=\"image_resolution_\", type=\"double\", bounds=dict(min=0.5, max=1)), \n","\n","  ],\n","  metrics=[\n","    dict(name=\"peak_memory[mB]\", strategy = 'optimize', objective=\"minimize\"),\n","    dict(name=\"inference_time[sec]\", strategy = 'optimize', objective=\"minimize\"),\n","    dict(name=\"storage_memory[mB]\", strategy = 'store', objective=\"minimize\"),\n","  ],\n","  parallel_bandwidth=1,\n","  budget=400,\n","  )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W_vPqM039x37"},"source":["for run in experiment.loop():\n","  with run:\n","    \n","    \"Set hyperparameters\"\n","    in_channels_ = run.params.setdefault('in_channels_', 3)\n","    out_channels_ = run.params.setdefault('out_channels_', 10)\n","    kernel_size_ = run.params.setdefault('kernel_size_', 10)\n","    \n","    s = run.params.setdefault('stride_', 1)\n","    stride_ = (s, s)\n","\n","    p = s = run.params.setdefault('padding_', 1)\n","    padding_ = (p, p)\n","\n","    batch_size_ = run.params.setdefault('batch_size_', 10)\n","\n","    image_resolution_ = run.params.setdefault('image_resolution_', 0.5)\n","    image_size_ = run.params.setdefault('image_size_', 224)\n","\n","    x_image_dim, y_image_dim = np.ceil(image_resolution_ * image_size_).astype('int'), np.ceil(image_resolution_ * image_size_).astype('int')\n","\n","    \"Create Conv2d block\"\n","    m = nn.Conv2d(in_channels = in_channels_,\n","                  out_channels = out_channels_,\n","                  kernel_size = kernel_size_,\n","                  stride = stride_,\n","                  padding = padding_)\n","    \n","    \"Create a random input\"\n","    input = torch.randn(batch_size_,\n","                        in_channels_,\n","                        x_image_dim,\n","                        y_image_dim)\n","\n","    run.log_metric(\"peak_memory[mB]\", profile_model(model = m, input = input))\n","    run.log_metric(\"inference_time[sec]\", get_inference_time(model = m, input = input))\n","    run.log_metric(\"storage_memory[mB]\", get_model_size(model = m))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BRx-Cwz8bMWC"},"source":["\n","\n","\n","experiment_id = \" insert experiment ID \""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"10dNC3y61UWb"},"source":["data = pd.DataFrame([], columns=[\"in_channels_\",\n","                                 \"out_channels_\",\n","                                 \"kernel_size_\",\n","                                 \"stride_\",\n","                                 \"padding_\",\n","                                 \"batch_size_\",\n","                                 \"image_resolution_\",\n","                                 \"peak_memory[mB]\",\n","                                 \"inference_time[sec]\",\n","                                 \"storage_memory[mB]\",\n","                                 ])\n","\n","for run in sigopt.get_experiment(experiment_id=experiment_id).get_runs():\n","  \n","  tmp = run.assignments\n","\n","  tmp[run.values['peak_memory[mB]'].name] = run.values['peak_memory[mB]'].value\n","\n","  tmp[run.values['inference_time[sec]'].name] = run.values['inference_time[sec]'].value\n","\n","  tmp[run.values['storage_memory[mB]'].name] = run.values['storage_memory[mB]'].value\n","\n","\n","  data = data.append(tmp, ignore_index=True)\n","\n","data['input_size_'] = np.ceil(data['image_resolution_'] * data['image_size_'])\n","\n","data.drop(columns=['image_size_', 'image_resolution_'], inplace=True)\n","\n","data.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["parameters = data[[\"in_channels_\",\n","                   \"out_channels_\",\n","                   \"kernel_size_\",\n","                   \"stride_\",\n","                   \"padding_\",\n","                   \"batch_size_\",\n","                   \"input_size_\",]]\n","\n","\n","parameters.columns = [\"Input Channels\",\n","                      \"Output Channels\",\n","                      \"Kernel Size\",\n","                      \"Stride\",\n","                      \"Padding\",\n","                      \"Batch Size\",\n","                      \"Input Size\",]\n","\n","\n","metrics = data[['inference_time[sec]',\n","                'peak_memory[mB]',\n","                'storage_memory[mB]',]]\n","\n","metrics_log = np.log(metrics)\n","\n","metrics_log.columns = ['log(Inference Time)',\n","                       'log(Peak Memory)',\n","                       'log(Storage Memory)']\n","\n","data_log = pd.concat([parameters, metrics_log], axis=1)"],"metadata":{"id":"_TlCFkiB5wuT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["con_inference_time = metrics['inference_time[sec]'].quantile(0.25)\n","con_peak_memory = metrics['peak_memory[mB]'].quantile(0.25)\n","con_storage_memory = metrics['storage_memory[mB]'].quantile(0.25)\n","\n","hue = pd.DataFrame([(metrics['storage_memory[mB]'] < con_storage_memory),\n","                  (metrics['peak_memory[mB]'] < con_peak_memory),\n","                  (metrics['storage_memory[mB]'] < con_storage_memory)]).all()\n","\n","hue.name = 'Constraints'\n","\n","hue[hue == False] = 'Outside'\n","hue[hue == True] = 'Inside'\n","\n","hue_order = hue.sort_values(ascending=False)"],"metadata":{"id":"pNWp5APrSU4T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.set_theme(style=\"ticks\")\n","plot_metrics = sns.pairplot(metrics_log,\n","                            diag_kind=\"kde\")\n","\n","plot_metrics.fig.suptitle('Pair Plot of Application Specific Metrics',\n","                          y=1.04,\n","                          fontsize = 25)"],"metadata":{"id":"AC6DqhLLxDJM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tmp = pd.concat([metrics_log, hue], axis=1)\n","tmp = tmp.sort_values(by = 'Constraints', ascending=False)\n","\n","sns.set_theme(style=\"ticks\")\n","\n","plot_metrics = sns.pairplot(tmp,\n","                            hue='Constraints')\n","\n","plot_metrics.fig.suptitle('Pair Plot of Application Specific Metrics',\n","                          y=1.04,\n","                          fontsize = 25)\n","\n","plot_metrics._legend.remove()"],"metadata":{"id":"NsldNuw8VbXN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","sns.set_theme(style=\"ticks\")\n","\n","plot_all = sns.pairplot(data_log,\n","                        diag_kind=\"kde\",\n","                        y_vars=list(metrics_log),\n","                        x_vars=list(data_log))\n","\n","plot_all.fig.suptitle('Pair Plot of Application Specific Metrics Including Relevant Hyperparameters',\n","                       y=1.04,\n","                       fontsize = 25)\n"],"metadata":{"id":"ILIafgvS1lQZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tmp = pd.concat([data_log, hue], axis=1)\n","tmp = tmp.sort_values(by = 'Constraints', ascending=False)\n","\n","sns.set_theme(style=\"ticks\")\n","\n","plot_all = sns.pairplot(tmp,\n","                        diag_kind=\"kde\",\n","                        hue = 'Constraints',\n","                        y_vars=list(metrics_log),\n","                        x_vars=list(data_log))\n","\n","plot_all.fig.suptitle('Pair Plot of Application Specific Metrics Including Relevant Hyperparameters',\n","                       y=1.04,\n","                       fontsize = 25)\n","\n","plot_all._legend.remove()"],"metadata":{"id":"UbPjcSlGW5qB"},"execution_count":null,"outputs":[]}]}